{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6324fb6e",
   "metadata": {},
   "source": [
    "# 时序异常检测基准测试框架\n",
    "\n",
    "这个notebook是整个基准测试框架的核心运行脚本，用于:\n",
    "- 加载和管理实验配置\n",
    "- 数据集处理（未完成）\n",
    "- 执行完整的模型训练和评估流程\n",
    "- 生成结果报告和可视化（待添加新评估图像和指标）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca78605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入依赖库\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c486a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 放在任何 torch 操作之前（越靠前越好）\n",
    "# import os\n",
    "\n",
    "# # 1) 让 MIOpen 避免在第一次做耗时的穷举搜索（显著减少“第一次超久”）\n",
    "# os.environ['MIOPEN_FIND_ENFORCE'] = '1'  # 只用已知解，跳过搜索\n",
    "# # 可选：自定义/确保可写缓存目录，避免权限问题导致每次都重新搜索\n",
    "# os.environ['MIOPEN_CACHE_DIR'] = os.path.expanduser('~/.cache/miopen')\n",
    "\n",
    "# # 2) 可选：看日志定位问题时再启用\n",
    "# # os.environ['MIOPEN_LOG_LEVEL'] = '5'\n",
    "\n",
    "# # 3) 限定可见 GPU（如有多卡）\n",
    "# # os.environ['HIP_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# # 4) 小型 warmup，提前完成 HIP/MIOpen 初始化（放在创建模型前）\n",
    "# import torch\n",
    "# if torch.cuda.is_available():\n",
    "#     x = torch.randn(128, 128, device='cuda')\n",
    "#     y = x @ x.t()\n",
    "#     torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6ea3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.base_model:注册模型: isolation_forest\n",
      "INFO:models.base_model:注册模型: iforest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目根目录: /home/chen/dev/fault_diagnosis_lib/benchmark\n",
      "依赖库导入完成\n",
      "ConfigManager 导入成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.base_model:注册模型: lstm_autoencoder\n",
      "INFO:models.base_model:注册模型: lstm_ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPipeline 导入成功\n",
      "ModelFactory 导入成功\n",
      "Trainer 导入成功\n",
      "Metrics 导入成功\n",
      "导入检测完成\n"
     ]
    }
   ],
   "source": [
    "# 添加项目路径\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"项目根目录: {project_root}\")\n",
    "print(\"依赖库导入完成\")\n",
    "\n",
    "# 分步导入框架组件\n",
    "try:\n",
    "    from src.config_manager import ConfigManager\n",
    "    print(\"ConfigManager 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"ConfigManager 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.dataloaders import DataPipeline\n",
    "    print(\"DataPipeline 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"DataPipeline 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    from models.base_model import ModelFactory\n",
    "    print(\"ModelFactory 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"ModelFactory 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.trainer import Trainer\n",
    "    print(\"Trainer 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"Trainer 导入失败: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.metrics import TimeSeriesEvaluator, print_evaluation_report\n",
    "    print(\"Metrics 导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"Metrics 导入失败: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# 设置随机种子\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"导入检测完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347131f",
   "metadata": {},
   "source": [
    "## 1. 配置管理与实验设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56150bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.config_manager:配置管理器初始化完成，配置目录: /home/chen/dev/fault_diagnosis_lib/benchmark/configs/default_experiment.yaml\n",
      "INFO:src.config_manager:配置文件加载成功: /home/chen/dev/fault_diagnosis_lib/benchmark/configs/default_experiment.yaml\n",
      "INFO:src.config_manager:配置验证通过\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验配置:\n",
      "   - 实验名称: benchmark_experiment_01\n",
      "   - 数据集: NPY_UCI_HAR\n",
      "   - 模型: ['iforest', 'lstm_ae']\n",
      "   - 评估指标: ['f1', 'precision', 'recall', 'auc', 'f1_point_adjusted']\n",
      "   - 结果保存: True\n"
     ]
    }
   ],
   "source": [
    "# 加载用户的实验配置\n",
    "config_file = project_root / 'configs' / 'default_experiment.yaml'\n",
    "# config_file = \"/home/chen/dev/fault_diagnosis_lib/benchmark/configs/default_experiment.yaml\"\n",
    "config_manager = ConfigManager(config_dir = config_file)\n",
    "config = config_manager.load_config()\n",
    "\n",
    "print(\"实验配置:\")\n",
    "print(f\"   - 实验名称: {config['experiment']['name']}\")\n",
    "print(f\"   - 数据集: {config['data']['dataset']}\")\n",
    "print(f\"   - 模型: {list(config['models'].keys())}\")\n",
    "print(f\"   - 评估指标: {config['evaluation']['metrics']}\")\n",
    "print(f\"   - 结果保存: {config['output']['save_results']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21c6ad",
   "metadata": {},
   "source": [
    "## 2. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64f4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.dataloaders:未提供预处理配置，使用默认值。\n",
      "INFO:src.dataloaders:开始数据加载和预处理...\n",
      "INFO:src.dataloaders:加载预分割数据集...\n",
      "INFO:src.dataloaders:加载器已提供预分割数据。\n",
      "INFO:src.dataloaders:数据准备完成。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据集: NPY_UCI_HAR\n",
      "Project root path: /home/chen/dev/fault_diagnosis_lib/benchmark\n",
      "Loading file: /home/chen/dev/fault_diagnosis_lib/benchmark/data/NPY_UCI_HAR/train_X.npy\n",
      "Project root path: /home/chen/dev/fault_diagnosis_lib/benchmark\n",
      "Loading file: /home/chen/dev/fault_diagnosis_lib/benchmark/data/NPY_UCI_HAR/train_y.npy\n",
      "Project root path: /home/chen/dev/fault_diagnosis_lib/benchmark\n",
      "Loading file: /home/chen/dev/fault_diagnosis_lib/benchmark/data/NPY_UCI_HAR/test_X.npy\n",
      "Project root path: /home/chen/dev/fault_diagnosis_lib/benchmark\n",
      "Loading file: /home/chen/dev/fault_diagnosis_lib/benchmark/data/NPY_UCI_HAR/test_y.npy\n",
      "Metadata: DataMetadata(dataset_name='NPY_UCI_HAR', fault_type='multi-class', feature_dim=9, num_classes=6, timesteps=128, number_train_samples=7352, number_test_samples=2947)\n",
      "No normalization applied.\n"
     ]
    }
   ],
   "source": [
    "# 创建数据管道\n",
    "data_pipeline = DataPipeline(config)\n",
    "\n",
    "# 加载数据\n",
    "dataset_name = config['data']['dataset']\n",
    "print(f\"加载数据集: {dataset_name}\")\n",
    "\n",
    "# get train_data, train_label, test_data, test_label, metadata\n",
    "train_data, test_data, train_label, test_label, metadata = data_pipeline.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e4cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据形状: (7352, 128, 9), 训练标签形状: (7352,)\n",
      "测试数据形状: (2947, 128, 9), 测试标签形状: (2947,)\n",
      "数据元信息: DataMetadata(dataset_name='NPY_UCI_HAR', fault_type='multi-class', feature_dim=9, num_classes=6, timesteps=128, number_train_samples=7352, number_test_samples=2947)\n"
     ]
    }
   ],
   "source": [
    "# show shapes\n",
    "print(f\"训练数据形状: {train_data.shape}, 训练标签形状: {train_label.shape}\")\n",
    "print(f\"测试数据形状: {test_data.shape}, 测试标签形状: {test_label.shape}\")\n",
    "print(f\"数据元信息: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b1b9d",
   "metadata": {},
   "source": [
    "## 3. 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57b3408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始模型训练与评估\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 初始化结果存储\n",
    "experiment_results = {}\n",
    "model_objects = {}\n",
    "\n",
    "# 创建评估器\n",
    "evaluator = TimeSeriesEvaluator(tolerance=config['evaluation']['tolerance'])\n",
    "\n",
    "print(\"开始模型训练与评估\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88db918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.base_model:初始化模型: LSTM_AutoEncoder\n",
      "INFO:models.lstm_ae:使用设备: cuda\n",
      "INFO:models.lstm_ae:LSTM AutoEncoder配置: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.2, 'bidirectional': False, 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 100, 'patience': 10, 'normalize': True, 'sequence_length': 50, 'device': 'cuda', 'lr': 0.001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM AutoEncoder\n",
      "----------------------------------------\n",
      "训练模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.lstm_ae:LSTM AutoEncoder模型构建完成\n",
      "INFO:models.lstm_ae:模型参数数量: 119625\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m训练模型...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 预测\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m生成预测...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fault_diagnosis_lib/benchmark/models/lstm_ae.py:200\u001b[39m, in \u001b[36mLSTMAutoEncoderModel.fit\u001b[39m\u001b[34m(self, X_train, y_train, metadata)\u001b[39m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_model(X_train.shape, metadata)\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# 数据预处理\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m X_processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_scaler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# 转换为序列数据\u001b[39;00m\n\u001b[32m    203\u001b[39m X_sequences = \u001b[38;5;28mself\u001b[39m._create_sequences(X_processed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fault_diagnosis_lib/benchmark/models/lstm_ae.py:340\u001b[39m, in \u001b[36mLSTMAutoEncoderModel._preprocess_data\u001b[39m\u001b[34m(self, X, fit_scaler)\u001b[39m\n\u001b[32m    338\u001b[39m         logger.info(\u001b[33m\"\u001b[39m\u001b[33m数据标准化器已拟合\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m         X_processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    342\u001b[39m     X_processed = X.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venv_py311_rocm/lib64/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venv_py311_rocm/lib64/python3.11/site-packages/sklearn/preprocessing/_data.py:541\u001b[39m, in \u001b[36mMinMaxScaler.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    529\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[32m    530\u001b[39m \n\u001b[32m    531\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m \u001b[33;03m        Transformed data.\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    543\u001b[39m     xp, _ = get_namespace(X)\n\u001b[32m    545\u001b[39m     X = validate_data(\n\u001b[32m    546\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    547\u001b[39m         X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    552\u001b[39m         reset=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    553\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venv_py311_rocm/lib64/python3.11/site-packages/sklearn/utils/validation.py:1754\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# 训练和评估 LSTM AutoEncoder\n",
    "if 'lstm_ae' in config['models']:\n",
    "    print(\"\\nLSTM AutoEncoder\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 创建模型\n",
    "    lstm_config = config['models']['lstm_ae']\n",
    "    model = ModelFactory.create_model('lstm_ae', lstm_config)\n",
    "    \n",
    "    # 训练\n",
    "    print(\"训练模型...\")\n",
    "    model.fit(train_data, train_label)\n",
    "    \n",
    "    # 预测\n",
    "    print(\"生成预测...\")\n",
    "    anomaly_scores = model.predict(test_data, metadata)\n",
    "    \n",
    "    # 评估\n",
    "    print(\"评估性能...\")\n",
    "    results = evaluator.evaluate(test_label, anomaly_scores, metadata)\n",
    "    \n",
    "    # 存储结果\n",
    "    experiment_results['lstm_ae'] = results\n",
    "    model_objects['lstm_ae'] = model\n",
    "    \n",
    "    # 显示结果\n",
    "    print_evaluation_report(results, \"LSTM AutoEncoder 评估结果\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5a977",
   "metadata": {},
   "source": [
    "## 4. 结果对比与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64496442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果汇总对比\n",
    "if experiment_results:\n",
    "    print(\"\\n模型性能对比\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 创建对比表格\n",
    "    comparison_metrics = ['f1', 'precision', 'recall', 'auc', 'f1_point_adjusted']\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, results in experiment_results.items():\n",
    "        row = {'模型': model_name}\n",
    "        for metric in comparison_metrics:\n",
    "            if metric in results:\n",
    "                value = results[metric]\n",
    "                if isinstance(value, float) and not np.isnan(value):\n",
    "                    row[metric] = f\"{value:.4f}\"\n",
    "                else:\n",
    "                    row[metric] = \"N/A\"\n",
    "            else:\n",
    "                row[metric] = \"N/A\"\n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    # 显示对比表格\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # 找出最佳模型\n",
    "    best_model = None\n",
    "    best_f1 = -1\n",
    "    \n",
    "    for model_name, results in experiment_results.items():\n",
    "        if 'f1' in results and not np.isnan(results['f1']):\n",
    "            if results['f1'] > best_f1:\n",
    "                best_f1 = results['f1']\n",
    "                best_model = model_name\n",
    "    \n",
    "    if best_model:\n",
    "        print(f\"\\n最佳模型: {best_model} (F1 Score: {best_f1:.4f})\")\n",
    "else:\n",
    "    print(\"没有成功的实验结果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化结果\n",
    "if experiment_results and config['output']['generate_plots']:\n",
    "    print(\"\\nGenerating visualization charts\")\n",
    "    \n",
    "    # Set plot style\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Time Series Anomaly Detection Benchmark Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Performance metrics bar chart\n",
    "    ax1 = axes[0, 0]\n",
    "    metrics_to_plot = ['f1', 'precision', 'recall']\n",
    "    model_names = list(experiment_results.keys())\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35 if len(model_names) == 2 else 0.25\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        values = []\n",
    "        for metric in metrics_to_plot:\n",
    "            value = experiment_results[model_name].get(metric, 0)\n",
    "            if isinstance(value, float) and not np.isnan(value):\n",
    "                values.append(value)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        \n",
    "        ax1.bar(x + i * width, values, width, label=model_name, alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Metric')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Performance Comparison')\n",
    "    ax1.set_xticks(x + width * (len(model_names) - 1) / 2)\n",
    "    ax1.set_xticklabels(metrics_to_plot)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Anomaly score distribution (example for first model)\n",
    "   \n",
    "    \n",
    "    # 3. Time series anomaly detection example (first 200 points)\n",
    "    ax3 = axes[1, 0]\n",
    "    n_points = min(200, len(test_labels))\n",
    "    time_indices = np.arange(n_points)\n",
    "    \n",
    "    # Show data for the first feature\n",
    "    ax3.plot(time_indices, test_data[:n_points, 0], 'b-', alpha=0.7, label='Time Series')\n",
    "    \n",
    "    # Mark anomaly points\n",
    "    anomaly_indices = np.where(test_labels[:n_points] == 1)[0]\n",
    "    if len(anomaly_indices) > 0:\n",
    "        ax3.scatter(anomaly_indices, test_data[anomaly_indices, 0], \n",
    "                   color='red', s=50, label='True Anomaly', zorder=5)\n",
    "    \n",
    "    ax3.set_xlabel('Time Index')\n",
    "    ax3.set_ylabel('Feature Value')\n",
    "    ax3.set_title('Time Series Anomaly Detection Example')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Confusion matrix (for best model)\n",
    "    if best_model:\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import itertools\n",
    "        \n",
    "        ax4 = axes[1, 1]\n",
    "        best_results = experiment_results[best_model]\n",
    "        \n",
    "        # Get best model predictions (binarized)\n",
    "        best_model_obj = model_objects[best_model]\n",
    "        if best_model == 'iforest':\n",
    "            best_pred = best_model_obj.predict(test_data)\n",
    "        elif best_model == 'lstm_ae':\n",
    "            best_pred = (best_model_obj.predict(test_data, metadata) > np.percentile(best_model_obj.predict(train_data, metadata), 90)).astype(int)\n",
    "        else:\n",
    "            best_pred = np.zeros_like(test_labels)\n",
    "        \n",
    "        cm = confusion_matrix(test_labels, best_pred)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax4)\n",
    "        ax4.set_xlabel('Predicted Label')\n",
    "        ax4.set_ylabel('True Label')\n",
    "        ax4.set_title(f'{best_model} Confusion Matrix')\n",
    "        ax4.xaxis.set_ticklabels(['Normal', 'Anomaly'])\n",
    "        ax4.yaxis.set_ticklabels(['Normal', 'Anomaly'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Visualization charts generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc99929",
   "metadata": {},
   "source": [
    "## 5. 结果保存与报告生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存实验结果\n",
    "if config['output']['save_results'] and experiment_results:\n",
    "    print(\"\\nSaving experiment results\")\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = project_root / config['output']['results_dir']\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    experiment_name = config['experiment']['name']\n",
    "    \n",
    "    # 保存详细结果，修正元数据字段\n",
    "    train_size = train_data.shape[0] if 'train_data' in locals() else None\n",
    "    test_size = test_data.shape[0] if 'test_data' in locals() else None\n",
    "    anomaly_rate = (np.sum(test_labels) / len(test_labels)) if 'test_labels' in locals() else None\n",
    "    detailed_results = {\n",
    "        'experiment_info': config['experiment'],\n",
    "        'data_info': {\n",
    "            'dataset': getattr(metadata, 'dataset_name', 'unknown'),\n",
    "            'n_features': getattr(metadata, 'feature_dim', None),\n",
    "            'train_size': train_size,\n",
    "            'test_size': test_size,\n",
    "            'anomaly_rate': anomaly_rate,\n",
    "            'fault_type': getattr(metadata, 'fault_type', None)\n",
    "        },\n",
    "        'model_results': experiment_results,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "print(\"结果保存功能待细化\")\n",
    "\n",
    "    # 保存为YAML文件\n",
    "    # results_file = results_dir / f\"{experiment_name}_{timestamp}.yaml\"\n",
    "    # with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    #     yaml.dump(detailed_results, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    # print(f\"Results saved to: {results_file}\")\n",
    "    \n",
    "    # # 保存对比表格为CSV\n",
    "    # if 'comparison_df' in locals():\n",
    "    #     csv_file = results_dir / f\"{experiment_name}_{timestamp}_comparison.csv\"\n",
    "    #     comparison_df.to_csv(csv_file, index=False)\n",
    "    #     print(f\"Comparison table saved to: {csv_file}\")\n",
    "    \n",
    "    # # 保存可视化图表\n",
    "    # if config['output']['generate_plots']:\n",
    "    #     plot_file = results_dir / f\"{experiment_name}_{timestamp}_plots.png\"\n",
    "    #     if 'fig' in locals():\n",
    "    #         fig.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    #         print(f\"Plot saved to: {plot_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb395a",
   "metadata": {},
   "source": [
    "## 6. 实验总结与建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成实验总结报告\n",
    "print(\"\\n实验总结报告\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"实验名称: {config['experiment']['name']}\")\n",
    "print(f\"数据集: {metadata.dataset_name}\")\n",
    "\n",
    "print(f\"评估指标: {', '.join(config['evaluation']['metrics'])}\")\n",
    "\n",
    "if experiment_results:\n",
    "    print(f\"\\n主要发现:\")\n",
    "    \n",
    "    # 分析各模型性能\n",
    "    for model_name, results in experiment_results.items():\n",
    "        f1_score = results.get('f1', 0)\n",
    "        precision = results.get('precision', 0)\n",
    "        recall = results.get('recall', 0)\n",
    "        \n",
    "        print(f\" - {model_name}: F1={f1_score:.4f}, Precision={precision:.4f}, Recall={recall:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "print(\"\\n基准测试实验完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量实验示例（可选运行）\n",
    "def run_batch_experiments(base_config, param_grid):\n",
    "    \"\"\"\n",
    "    运行批量实验进行参数扫描\n",
    "    \n",
    "    Args:\n",
    "        base_config: 基础配置\n",
    "        param_grid: 参数网格\n",
    "    \"\"\"\n",
    "    batch_results = []\n",
    "    \n",
    "    for i, params in enumerate(param_grid):\n",
    "        print(f\"\\n 批量实验 {i+1}/{len(param_grid)}\")\n",
    "        \n",
    "        # 更新配置\n",
    "        current_config = base_config.copy()\n",
    "        for key, value in params.items():\n",
    "            # 支持嵌套键如 'models.iforest.n_estimators'\n",
    "            keys = key.split('.')\n",
    "            target = current_config\n",
    "            for k in keys[:-1]:\n",
    "                target = target[k]\n",
    "            target[keys[-1]] = value\n",
    "        \n",
    "        # 运行实验（这里简化为示例）\n",
    "        print(f\"   参数: {params}\")\n",
    "        \n",
    "        # TODO: 在这里添加完整的实验流程\n",
    "        # 这需要重构上面的代码为函数形式\n",
    "        \n",
    "        batch_results.append({\n",
    "            'params': params,\n",
    "            'results': {}  # 实际结果\n",
    "        })\n",
    "    \n",
    "    return batch_results\n",
    "\n",
    "# 示例参数网格（实际使用时取消注释）\n",
    "# param_grid = [\n",
    "#     {'models.iforest.n_estimators': 50, 'models.iforest.contamination': 0.05},\n",
    "#     {'models.iforest.n_estimators': 100, 'models.iforest.contamination': 0.1},\n",
    "#     {'models.iforest.n_estimators': 200, 'models.iforest.contamination': 0.15},\n",
    "# ]\n",
    "\n",
    "# # 运行批量实验\n",
    "# batch_results = run_batch_experiments(config, param_grid)\n",
    "\n",
    "print(\"批量实验功能待定义\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py311_rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
