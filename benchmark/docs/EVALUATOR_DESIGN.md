# è¯„ä¼°å™¨è®¾è®¡è§„èŒƒ

## ğŸ“ è®¾è®¡åŸåˆ™

### æ ¸å¿ƒæ€æƒ³
1. **è¯„ä¼°å™¨åªè´Ÿè´£è®¡ç®—å’Œè¿”å›ç»“æœ**ï¼Œä¸å¤„ç†ä¿å­˜é€»è¾‘
2. **EvalLoader è´Ÿè´£æ ¹æ®ä¸Šä¸‹æ–‡å¤„ç†è¿”å›å€¼**ï¼Œç‰¹åˆ«æ˜¯å›¾åƒçš„ä¿å­˜ä½ç½®
3. **ç§»é™¤è¯„ä¼°å™¨å†…éƒ¨çš„å…¨å±€çŠ¶æ€ä¾èµ–**ï¼Œä½¿è¯„ä¼°å™¨æ›´çº¯ç²¹å’Œå¯æµ‹è¯•

---

## ğŸ¯ è¯„ä¼°å™¨è¿”å›å€¼è§„èŒƒ

è¯„ä¼°å™¨å¯ä»¥è¿”å›ä»¥ä¸‹ç±»å‹ï¼š

### 1. **æ•°å€¼å‹** (æ¨è)
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """è®¡ç®—å‡†ç¡®ç‡"""
    accuracy = (y_test_pred == y_test).mean()
    return accuracy  # float
```

### 2. **å­—ç¬¦ä¸²å‹**
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """è¿”å›æ–‡æœ¬ä¿¡æ¯"""
    return f"å‡†ç¡®ç‡: {accuracy:.2%}"  # str
```

### 3. **å›¾åƒå‹** (matplotlib Figure)
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """ç”Ÿæˆå›¾è¡¨"""
    fig = plt.figure(figsize=(10, 6))
    # ... ç»˜å›¾ä»£ç  ...
    plt.tight_layout()
    return fig  # matplotlib.figure.Figure
```

### 4. **å›¾åƒ+æ•°å€¼å‹** (æ¨èç”¨äºç»˜å›¾è¯„ä¼°å™¨)
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """ç”Ÿæˆå›¾è¡¨å¹¶è¿”å›æŒ‡æ ‡"""
    fig = plt.figure(figsize=(10, 6))
    # ... ç»˜å›¾ä»£ç  ...
    plt.tight_layout()
    
    metric_value = len(y_test)  # æˆ–å…¶ä»–æœ‰æ„ä¹‰çš„æ•°å€¼
    return (fig, metric_value)  # tuple: (Figure, float)
```

---

## ğŸ”§ EvalLoader è‡ªåŠ¨å¤„ç†é€»è¾‘

### å›¾åƒä¿å­˜è§„åˆ™

#### **è®­ç»ƒè¿‡ç¨‹ä¸­** (epoch_info ä¸ä¸º None)
```python
eval_loader.set_context(
    plots_dir='/path/to/plots',
    epoch_info={'epoch': 10},  # ç¬¬10è½®
    logging_level='normal'
)
```
**ä¿å­˜ä½ç½®**: `plots/epochinfo/metric_name_epoch_011.png`

#### **æœ€ç»ˆè¯„ä¼°** (epoch_info ä¸º None)
```python
eval_loader.set_context(
    plots_dir='/path/to/plots',
    epoch_info=None,  # æœ€ç»ˆè¯„ä¼°
    logging_level='normal'
)
```
**ä¿å­˜ä½ç½®**: `plots/metric_name.png`

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹1: ç®€å•æ•°å€¼è¯„ä¼°å™¨
```python
# evaluators/accuracy.py
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡"""
    return (y_test_pred == y_test).mean()
```

### ç¤ºä¾‹2: ç»˜å›¾è¯„ä¼°å™¨
```python
# evaluators/confusion_matrix_plot.py
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    
    Returns:
        tuple: (Figureå¯¹è±¡, å‡†ç¡®ç‡)
    """
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_test_pred)
    
    # åˆ›å»ºå›¾åƒ
    fig, ax = plt.subplots(figsize=(10, 8))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(ax=ax, cmap='Blues')
    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = (y_test_pred == y_test).mean()
    
    # è¿”å›Figureå’Œå‡†ç¡®ç‡
    # EvalLoaderä¼šè‡ªåŠ¨ä¿å­˜å›¾åƒåˆ°åˆé€‚ä½ç½®
    return (fig, accuracy)
```

### ç¤ºä¾‹3: çº¯æ–‡æœ¬è¯„ä¼°å™¨
```python
# evaluators/dataset_summary.py
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    """è¿”å›æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    return f"Train: {len(y_train)}, Test: {len(y_test)}"
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åœ¨ main.py ä¸­ï¼ˆæœ€ç»ˆè¯„ä¼°ï¼‰
```python
# è®¾ç½®è¯„ä¼°ä¸Šä¸‹æ–‡
eval_loader.set_context(
    plots_dir=plots_dir,
    epoch_info=None,  # Noneè¡¨ç¤ºæœ€ç»ˆè¯„ä¼°
    logging_level='normal'
)

# æ‰§è¡Œè¯„ä¼°ï¼ˆå›¾åƒä¼šè‡ªåŠ¨ä¿å­˜åˆ° plots/ ç›®å½•ï¼‰
eval_results = eval_loader.evaluate(
    config, 'basic_metrics',
    X_train, y_train, train_pred,
    X_test, y_test, test_pred
)
```

### åœ¨ epochinfo_loader.py ä¸­ï¼ˆè®­ç»ƒè¿‡ç¨‹ï¼‰
```python
# è®¾ç½®è¯„ä¼°ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«epochä¿¡æ¯ï¼‰
eval_loader.set_context(
    plots_dir=plots_dir,
    epoch_info={'epoch': epoch_num},  # æŒ‡å®šå½“å‰epoch
    logging_level='minimal'
)

# æ‰§è¡Œè¯„ä¼°ï¼ˆå›¾åƒä¼šè‡ªåŠ¨ä¿å­˜åˆ° plots/epochinfo/ ç›®å½•ï¼‰
eval_results = eval_loader.evaluate(
    config, 'basic_metrics',
    X_train, y_train, train_pred,
    X_test, y_test, test_pred
)
```

---

## âœ… ä¼˜åŠ¿æ€»ç»“

### æ—§è®¾è®¡çš„é—®é¢˜
- âŒ è¯„ä¼°å™¨éœ€è¦é€šè¿‡å…¨å±€å˜é‡è·å–é…ç½®
- âŒ éœ€è¦æ‰‹åŠ¨è°ƒç”¨ `set_plots_dir()`, `set_epoch_info()` ç­‰å‡½æ•°
- âŒ è¯„ä¼°å™¨å’Œæ¡†æ¶è€¦åˆåº¦é«˜
- âŒ éš¾ä»¥æµ‹è¯•å’Œå¤ç”¨

### æ–°è®¾è®¡çš„ä¼˜åŠ¿
- âœ… **è¯„ä¼°å™¨çº¯ç²¹**ï¼šåªè´Ÿè´£è®¡ç®—ï¼Œä¸å…³å¿ƒä¿å­˜é€»è¾‘
- âœ… **ç»Ÿä¸€å¤„ç†**ï¼šEvalLoader ç»Ÿä¸€å¤„ç†æ‰€æœ‰ç±»å‹çš„è¿”å›å€¼
- âœ… **æ˜“äºæ‰©å±•**ï¼šæ–°å¢è¯„ä¼°å™¨åªéœ€æŒ‰è§„èŒƒè¿”å›ç»“æœ
- âœ… **æ˜“äºæµ‹è¯•**ï¼šè¯„ä¼°å™¨æ˜¯çº¯å‡½æ•°ï¼Œæ–¹ä¾¿å•å…ƒæµ‹è¯•
- âœ… **çµæ´»é…ç½®**ï¼šé€šè¿‡ `set_context()` é›†ä¸­ç®¡ç†ä¸Šä¸‹æ–‡
- âœ… **è‡ªåŠ¨åŒ–**ï¼šå›¾åƒä¿å­˜ä½ç½®è‡ªåŠ¨æ ¹æ® epoch_info åˆ¤æ–­

---

## ğŸ”„ è¿ç§»æŒ‡å—

### æ—§çš„è¯„ä¼°å™¨ä»£ç 
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    fig = plt.figure()
    # ... ç»˜å›¾ ...
    
    # è·å–å…¨å±€å˜é‡
    plots_dir = getattr(evaluate, '_plots_dir', None)
    epoch_info = getattr(evaluate, '_epoch_info', None)
    
    # æ‰‹åŠ¨å¤„ç†ä¿å­˜é€»è¾‘
    if plots_dir:
        if epoch_info:
            path = f"{plots_dir}/epochinfo/plot_{epoch_info['epoch']}.png"
        else:
            path = f"{plots_dir}/plot.png"
        plt.savefig(path)
    plt.close()
    
    return metric_value
```

### æ–°çš„è¯„ä¼°å™¨ä»£ç 
```python
def evaluate(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred):
    fig = plt.figure()
    # ... ç»˜å›¾ ...
    plt.tight_layout()
    
    # ç›´æ¥è¿”å›Figureå¯¹è±¡ï¼Œè®©EvalLoaderå¤„ç†ä¿å­˜
    return (fig, metric_value)
```

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸ‰

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- **è¯„ä¼°å™¨æ¥å£**: `benchmark/src/eval_loader.py`
- **ç¤ºä¾‹è¯„ä¼°å™¨**: `benchmark/evaluators/plot_label_distribution.py`
- **è®­ç»ƒä¸­è°ƒç”¨**: `benchmark/src/epochinfo_loader.py`
- **æœ€ç»ˆè¯„ä¼°è°ƒç”¨**: `benchmark/main.py`
